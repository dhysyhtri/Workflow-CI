name: CI Workflow Amazon Sales (MLflow + Docker Stable)

on:
  push:
    branches: ["main"]
  workflow_dispatch:

env:
  DAGSHUB_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
  DAGSHUB_TOKEN: ${{ secrets.DAGSHUB_TOKEN }}
  MLFLOW_TRACKING_URI: "https://dagshub.com/dhysyhtri/amazon-sales-mlflow.mlflow"
  MLFLOW_TRACKING_USERNAME: ${{ secrets.DAGSHUB_USERNAME }}
  MLFLOW_TRACKING_PASSWORD: ${{ secrets.DAGSHUB_TOKEN }}

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
    # 1. Checkout repository
    - name: Checkout Code
      uses: actions/checkout@v3

    # 2. Set up Python 3.12.7
    - name: Set up Python 3.12.7
      uses: actions/setup-python@v4
      with:
        python-version: "3.12.7"

    # 3. Check Environment
    - name: Check Env
      run: |
        python --version
        pip --version
        ls -R

    # 4. Install Python dependencies
    - name: Install Dependencies
      run: |
        pip install --upgrade pip
        pip install mlflow==2.19.0 dagshub pandas numpy scikit-learn joblib cloudpickle

    # 5. Run MLflow Project (Training & logging metrics/params only)
    - name: Run MLflow Project
      run: |
        cd MLProject
        mlflow run . --env-manager=local --experiment-name "amazon-sales-ci"

    # 6. Get latest MLflow run_id
    - name: Get latest MLflow run_id
      id: get_run
      run: |
        run_id=$(python3 -c "import mlflow; runs=mlflow.search_runs(experiment_names=['amazon-sales-ci'], order_by=['start_time DESC'], max_results=1); print(runs.iloc[0].run_id)")
        echo "run_id=$run_id" >> $GITHUB_OUTPUT
        echo "Latest Run ID: $run_id"

    # 7. Upload model.pkl to GitHub Artifacts
    - name: Upload Model Artifact (.pkl)
      uses: actions/upload-artifact@v4
      with:
        name: amazon-sales-model
        path: MLProject/model.pkl

    # 8. Build Docker Image from model.pkl
    - name: Build Docker Image
      run: |
        cd MLProject
        IMAGE_NAME="${{ secrets.DOCKERHUB_USERNAME }}/amazon-mlflow-model"
        TAG="latest"

        # Dockerfile inline tanpa requirements.txt
        echo '
        FROM python:3.12-slim
        WORKDIR /app
        COPY model.pkl .
        RUN pip install --no-cache-dir pandas numpy scikit-learn joblib
        CMD ["python", "-c", "import joblib; model=joblib.load(\"model.pkl\"); print(\"Model siap digunakan\")"]
        ' > Dockerfile

        docker build -t "$IMAGE_NAME:$TAG" .

    # 9. Docker Login
    - name: Docker Login
      uses: docker/login-action@v3
      with:
        username: ${{ secrets.DOCKERHUB_USERNAME }}
        password: ${{ secrets.DOCKERHUB_TOKEN }}

    # 10. Push Docker Image
    - name: Push Docker Image
      run: |
        IMAGE_NAME="${{ secrets.DOCKERHUB_USERNAME }}/amazon-mlflow-model"
        TAG="latest"
        docker push "$IMAGE_NAME:$TAG"
